---
title: "TreeMethods"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Decision Trees

Create binary response variable 'High'

```{r}
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,'No','Yes')
Carseats=data.frame(Carseats,High)
```

Fit tree and exclude Sales due to response variable being derived from Sales

```{r}
tree.carseats=tree(High~. -Sales, data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
```

```{r}
tree.carseats
```

Create train/test sets (250/150) of the 400 observations
```{r}
set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~. -Sales, Carseats, subset=train)
plot(tree.carseats); text(tree.carseats,pretty=0)
tree.pred=predict(tree.carseats, Carseats[-train,],type='class')
with(Carseats[-train,],table(tree.pred,High))
(72+33)/150
```

```{r}
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
plot(cv.carseats)
prune.carseats=prune.misclass(tree.carseats,best=13)
plot(prune.carseats);text(prune.carseats,pretty=0)
```

```{r}
tree.pred=predict(prune.carseats, Carseats[-train,],type='class')
with(Carseats[-train,],table(tree.pred,High))
(72+32)/150
```

Random Forests and Boosting

```{r}
require(randomForest)
require(MASS)
set.seed(101)
dim(Boston)
train=sample(1:nrow(Boston), 300)
?Boston
```

```{r}
rf.boston=randomForest(medv~.,data=Boston,subset=train)
rf.boston
```

```{r}
oob.err=double(13)
test.err=double(13)
for(mtry in 1:13){
  fit=randomForest(medv~.,data=Boston,subset=train,mtry=mtry,ntree=400)
  oob.err[mtry]=fit$mse[400]
  pred=predict(fit,Boston[-train,])
  test.err[mtry]=with(Boston[-train,],mean((medv-pred)^2))
  cat(mtry,' ')
}
matplot(1:mtry,cbind(test.err,oob.err), pch=19, col=c('red','blue'),type='b',ylab='Mean Squared Error')
legend('topright', legend=c('OOB','Test'),pch=19,col=c('red','blue'))
```

```{r}
require(gbm)
boost.boston=gbm(medv~.,data=Boston[train,],distribution='gaussian',n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.boston)
plot(boost.boston,i='lstat')
plot(boost.boston, i='rm')
```

```{r}
n.trees=seq(from=100, to=10000,by=100)
predmat=predict(boost.boston, newdata=Boston[-train,],n.trees=n.trees)
dim(predmat)
berr=with(Boston[-train,], apply((predmat-medv)^2,2,mean))
plot(n.trees, berr, pch=19, ylab='mean squared error', xlab='# trees', main='Boosting Test Error')
abline(h=min(test.err), col='red')
```

```{r}

```

```{r}

```







