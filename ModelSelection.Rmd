---
title: "ModelSelection"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


```{r}
library(ISLR)
summary(Hitters)
```


```{r,echo=FALSE}
Hitters=na.omit(Hitters)
with(Hitters, sum(is.na(Salary)))
```

# Best Subset Regression

Leaps package to evaluate all of the best-subset models

```{r}
library(leaps)
regfit.full=regsubsets(Salary~., data=Hitters)
summary(regfit.full)
```

Outputs best-subsets up to size 8

Increase to 19 (all variables)
```{r}
regfit.full=regsubsets(Salary~., data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp, xlab='Number of Variables', ylab='Cp')
which.min(reg.summary$cp)
points(10, reg.summary$cp[10],pch=20,col='red')
```

```{r}
plot(regfit.full, scale='Cp')
coef(regfit.full,10)
```

Forward Stepwise Selection

forward method
```{r}

regfit.fwd=regsubsets(Salary~., data=Hitters, nvmax=19, method='forward')
summary(regfit.fwd)
plot(regfit.fwd, scale='Cp')
```


Model Selection Using a Validation Set

```{r}
dim(Hitters)
set.seed(1)
train=sample(seq(263), 180, replace=FALSE)
train
regfit.fwd=regsubsets(Salary~., data=Hitters[train,], nvmax=19, method='forward')
```

Make predictions on the test set
```{r}
val.errors=rep(NA, 19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])
for(i in 1:19){
  coefi=coef(regfit.fwd, id=i)
  pred=x.test[,names(coefi)]%*%coefi
  val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors), ylab='Root MSE', ylim=c(300,400),pch=19,type='b')
points(sqrt(regfit.fwd$rss[-1]/180), col='blue', pch=19, type='b')
legend('topright', legend=c('Training','Validation'), col=c('blue','black'),pch=19)
```

```{r}
predict.regsubsets=function(object, newdata, id, ...){
  form=as.formula(object$call[[2]])
  mat=model.matrix(form, newdata)
  coefi=coef(object, id=id)
  mat[,names(coefi)]%*%coefi
}

```


Model Selection by 10-fold Cross-Validation
```{r}
set.seed(11)
folds=sample(rep(1:10, length=nrow(Hitters)))
folds
table(folds)
cv.errors=matrix(NA,10,19)
for(k in 1:10){
  best.fit=regsubsets(Salary~., data=Hitters[folds!=k,], nvmax=19, method='forward')
  for(i in 1:19){
    pred=predict(best.fit, Hitters[folds==k,], id=i)
    cv.errors[k,i]=mean((Hitters$Salary[folds==k]-pred)^2)
  }
}

rmse.cv=sqrt(apply(cv.errors, 2, mean))
plot(rmse.cv, pch=19, type='b')

```
Lowest error at 11 or 12
Ridge and Lasso
```{r}
x=model.matrix(Salary~. -1, data=Hitters)
y=Hitters$Salary

```

Fit ridge regression with alpha=0
```{r}
#install.packages('glmnet')
library(glmnet)
fit.ridge=glmnet(x,y,alpha=0)
plot(fit.ridge, xvar='lambda',label=TRUE)
cv.ridge=cv.glmnet(x,y,alpha=0)
plot(cv.ridge)

```

Lasso model alpha=1
Performing shrinkage and variable selection
```{r}
fit.lasso=glmnet(x,y, alpha=1)
plot(fit.lasso, xvar='lambda', label=TRUE)
cv.lasso=cv.glmnet(x,y)
plot(cv.lasso)
coef(cv.lasso)

```

Use validation set to select lambda for lasso
```{r}
lasso.tr=glmnet(x[train,],y[train])
lasso.tr
pred=predict(lasso.tr,x[-train,])
dim(pred)
rmse=sqrt(apply((y[-train]-pred)^2,2,mean))
plot(log(lasso.tr$lambda), rmse, type='b', xlab='Log(lambda)')
lam.best=lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr,s=lam.best)
```



